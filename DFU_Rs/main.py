import os
import io
import torch
from fastapi import FastAPI, UploadFile, File
from fastapi.responses import FileResponse
import numpy as np
import cv2
from reportlab.lib.pagesizes import letter
from reportlab.pdfgen import canvas
from dfu_predictor import load_feature_extractor, DfuRecommender, TREATMENT_MAP, transform, predict_grade
from ultralytics import YOLO
from PIL import Image
from reportlab.lib.utils import ImageReader
# Set device
DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'

# Load models and paths
seg_model = YOLO("models/Instance_Segementation_Model.pt")
model_path = 'models/best_convnext.pth'
feats_path = 'npy_folder/dfu_feats.npy'
grades_path = 'npy_folder/dfu_grades.npy'
paths_path = 'npy_folder/dfu_paths.npy'

extractor = load_feature_extractor(model_path, device=DEVICE)
recommender = DfuRecommender(feats_path, grades_path, paths_path)

# Segmentation overlay
def run_instance_segmentation(pil_image):
    image = np.array(pil_image)
    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
    results = seg_model.predict(image)
    annotated_image = image.copy()
    heatmap = np.zeros_like(image, dtype=np.float32)

    found_masks = False

    for result in results:
        if result.masks is None or result.boxes is None:
            continue
        for mask, box in zip(result.masks, result.boxes):
            found_masks = True
            mask_array = mask.data.cpu().numpy()
            if mask_array.shape[1:] != annotated_image.shape[:2]:
                mask_array = cv2.resize(mask_array[0], (annotated_image.shape[1], annotated_image.shape[0]))
            mask_array_rgb = np.stack([mask_array] * 3, axis=-1)
            heatmap += mask_array_rgb.astype(np.float32)

    if not found_masks:
        return None, False

    heatmap = cv2.normalize(heatmap, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
    heatmap_color = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)
    overlay = cv2.addWeighted(annotated_image, 0.6, heatmap_color, 0.4, 0)
    overlay = cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB)
    return Image.fromarray(overlay), True

app = FastAPI()

@app.post("/predict")
async def predict_and_generate_pdf(file: UploadFile = File(...)):
    print("Received file:", file.filename)
    contents = await file.read()
    img = Image.open(io.BytesIO(contents)).convert('RGB')
    heatmap_img, found_ulcer = run_instance_segmentation(img)

    pdf_path = "treatment_report.pdf"
    c = canvas.Canvas(pdf_path, pagesize=letter)
    width, height = letter

    if not found_ulcer:
        # Minimal report for non-DFU images
        c.setFont("Helvetica-Bold", 18)
        c.drawString(50, height - 50, "DFU Screening Report")
        c.setFont("Helvetica", 12)
        c.drawString(50, height - 80, "Result: This image does not appear to show a Diabetic Foot Ulcer (DFU).")
        c.drawString(50, height - 100, "Please ensure the input image is of sufficient quality and shows a relevant foot region.")
        c.setFont("Helvetica-Oblique", 9)
        c.drawString(50, 40, "This report is generated by an AI model. Clinical validation is advised.")
        c.save()
        return FileResponse(path=pdf_path, filename="dfu_screening_report.pdf", media_type='application/pdf')

    # -------- DFU detected — proceed normally --------
    img_t = transform(img)
    predicted_grade = predict_grade(img_t, model_path, device=DEVICE)
    recs = recommender.recommend(img_t, extractor, k=2, device=DEVICE)

    # Header
    c.setFont("Helvetica-Bold", 18)
    c.drawString(50, height - 50, "Diabetic Foot Ulcer Treatment Report")
    c.setFont("Helvetica", 12)
    c.drawString(50, height - 70, f"Classification Model: ConvNeXt (fine-tuned)")
    c.drawString(50, height - 85, f"Instance Segmentation Model: Yolov11")
    c.drawString(50, height - 100, f"Predicted Wagner–Meggitt Classification Grade: {predicted_grade}")

    # Images
    y = height - 140
    img_orig = img.copy(); img_orig.thumbnail((160, 160))
    heatmap_img.thumbnail((160, 160))
    c.drawString(50, y, "Input Image")
    c.drawString(250, y, "Segmentation Overlay")
    y -= 20
    c.drawImage(ImageReader(img_orig), 50, y - 160, width=150, height=150)
    c.drawImage(ImageReader(heatmap_img), 250, y - 160, width=150, height=150)
    y -= 180

    # Treatment Plan
    c.setFont("Helvetica-Bold", 12)
    c.drawString(50, y, "Recommended Treatment Plan:")
    c.setFont("Helvetica", 11)
    for step in TREATMENT_MAP[predicted_grade]:
        c.drawString(70, y - 15, f"- {step}")
        y -= 15
    y -= 15

    # Similar Cases
    c.setFont("Helvetica-Bold", 12)
    c.drawString(50, y, "Most Similar Cases:")
    c.setFont("Helvetica", 11)
    y -= 20

    for idx, rec in enumerate(recs, 1):
        if y < 150:
            c.showPage()
            y = height - 50

        grade_folder = f"Grade {int(rec['grade'])}"
        img_filename = os.path.basename(rec['path'])
        corrected_path = os.path.join("data", grade_folder, img_filename)

        c.setFont("Helvetica-Bold", 11)
        c.drawString(50, y, f"{idx}. Similar Patient")
        c.setFont("Helvetica", 11)
        c.drawString(70, y - 15, f"Wagner Grade: {rec['grade']}")

        try:
            case_img = Image.open(corrected_path).convert('RGB')
            case_img.thumbnail((120, 120))
            c.drawImage(ImageReader(case_img), 50, y - 140, width=120, height=120)
        except Exception as e:
            c.drawString(70, y - 30, f"[Image load failed: {e}]")

        y -= 150

    # Footer
    c.setFont("Helvetica-Oblique", 9)
    c.drawString(50, 40, "This report is generated by an AI model. Clinical validation is advised.")
    c.save()

    # Return PDF
    return FileResponse(path=pdf_path, filename="treatment_report.pdf", media_type='application/pdf')

# -----------------------------------------------------------
# -----------------------------------------------------------
# Incase we want to Jpeg instead of PDF
# -----------------------------------------------------------
# -----------------------------------------------------------


# import os
# import io
# import torch
# import cv2
# import numpy as np
# from fastapi import FastAPI, UploadFile, File
# from fastapi.responses import FileResponse
# from PIL import Image
# from reportlab.lib.pagesizes import letter
# from reportlab.pdfgen import canvas
# from reportlab.lib.utils import ImageReader
# from dfu_predictor import load_feature_extractor, DfuRecommender, TREATMENT_MAP, transform, predict_grade
# from ultralytics import YOLO
# from pdf2image import convert_from_path

# # Set device
# DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'

# # Load models and paths
# seg_model = YOLO("models/Instance_Segementation_Model.pt")
# model_path = 'models/best_convnext.pth'
# feats_path = 'npy_folder/dfu_feats.npy'
# grades_path = 'npy_folder/dfu_grades.npy'
# paths_path = 'npy_folder/dfu_paths.npy'

# extractor = load_feature_extractor(model_path, device=DEVICE)
# recommender = DfuRecommender(feats_path, grades_path, paths_path)

# # Segmentation overlay
# def run_instance_segmentation(pil_image):
#     image = np.array(pil_image)
#     image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
#     results = seg_model.predict(image)
#     annotated_image = image.copy()
#     heatmap = np.zeros_like(image, dtype=np.float32)

#     found_masks = False

#     for result in results:
#         if result.masks is None or result.boxes is None:
#             continue
#         for mask, box in zip(result.masks, result.boxes):
#             found_masks = True
#             mask_array = mask.data.cpu().numpy()
#             if mask_array.shape[1:] != annotated_image.shape[:2]:
#                 mask_array = cv2.resize(mask_array[0], (annotated_image.shape[1], annotated_image.shape[0]))
#             mask_array_rgb = np.stack([mask_array] * 3, axis=-1)
#             heatmap += mask_array_rgb.astype(np.float32)

#     if not found_masks:
#         return None, False

#     heatmap = cv2.normalize(heatmap, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
#     heatmap_color = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)
#     overlay = cv2.addWeighted(annotated_image, 0.6, heatmap_color, 0.4, 0)
#     overlay = cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB)
#     return Image.fromarray(overlay), True

# app = FastAPI()

# @app.post("/predict")
# async def predict_and_generate_pdf(file: UploadFile = File(...)):
#     print("Received file:", file.filename)
#     contents = await file.read()
#     img = Image.open(io.BytesIO(contents)).convert('RGB')
#     heatmap_img, found_ulcer = run_instance_segmentation(img)

#     pdf_path = "treatment_report.pdf"
#     c = canvas.Canvas(pdf_path, pagesize=letter)
#     width, height = letter

#     if not found_ulcer:
#         # Minimal report for non-DFU images
#         c.setFont("Helvetica-Bold", 18)
#         c.drawString(50, height - 50, "DFU Screening Report")
#         c.setFont("Helvetica", 12)
#         c.drawString(50, height - 80, "Result: This image does not appear to show a Diabetic Foot Ulcer (DFU).")
#         c.drawString(50, height - 100, "Please ensure the input image is of sufficient quality and shows a relevant foot region.")
#         c.setFont("Helvetica-Oblique", 9)
#         c.drawString(50, 40, "This report is generated by an AI model. Clinical validation is advised.")
#         c.save()
#         return FileResponse(path=pdf_path, filename="dfu_screening_report.pdf", media_type='application/pdf')

#     # -------- DFU detected — proceed normally --------
#     img_t = transform(img)
#     predicted_grade = predict_grade(img_t, model_path, device=DEVICE)
#     recs = recommender.recommend(img_t, extractor, k=2, device=DEVICE)

#     # Header
#     c.setFont("Helvetica-Bold", 18)
#     c.drawString(50, height - 50, "Diabetic Foot Ulcer Treatment Report")
#     c.setFont("Helvetica", 12)
#     c.drawString(50, height - 70, f"Classification Model: ConvNeXt (fine-tuned)")
#     c.drawString(50, height - 85, f"Instance Segmentation Model: Yolov11")
#     c.drawString(50, height - 100, f"Predicted Wagner–Meggitt Classification Grade: {predicted_grade}")

#     # Images
#     y = height - 140
#     img_orig = img.copy(); img_orig.thumbnail((160, 160))
#     heatmap_img.thumbnail((160, 160))
#     c.drawString(50, y, "Input Image")
#     c.drawString(250, y, "Segmentation Overlay")
#     y -= 20
#     c.drawImage(ImageReader(img_orig), 50, y - 160, width=150, height=150)
#     c.drawImage(ImageReader(heatmap_img), 250, y - 160, width=150, height=150)
#     y -= 180

#     # Treatment Plan
#     c.setFont("Helvetica-Bold", 12)
#     c.drawString(50, y, "Recommended Treatment Plan:")
#     c.setFont("Helvetica", 11)
#     for step in TREATMENT_MAP[predicted_grade]:
#         c.drawString(70, y - 15, f"- {step}")
#         y -= 15
#     y -= 15

#     # Similar Cases
#     c.setFont("Helvetica-Bold", 12)
#     c.drawString(50, y, "Most Similar Cases:")
#     c.setFont("Helvetica", 11)
#     y -= 20

#     for idx, rec in enumerate(recs, 1):
#         if y < 150:
#             c.showPage()
#             y = height - 50

#         grade_folder = f"Grade {int(rec['grade'])}"
#         img_filename = os.path.basename(rec['path'])
#         corrected_path = os.path.join("data", grade_folder, img_filename)

#         c.setFont("Helvetica-Bold", 11)
#         c.drawString(50, y, f"{idx}. Similar Patient")
#         c.setFont("Helvetica", 11)
#         c.drawString(70, y - 15, f"Wagner Grade: {rec['grade']}")

#         try:
#             case_img = Image.open(corrected_path).convert('RGB')
#             case_img.thumbnail((120, 120))
#             c.drawImage(ImageReader(case_img), 50, y - 140, width=120, height=120)
#         except Exception as e:
#             c.drawString(70, y - 30, f"[Image load failed: {e}]")

#         y -= 150

#     # Footer
#     c.setFont("Helvetica-Oblique", 9)
#     c.drawString(50, 40, "This report is generated by an AI model. Clinical validation is advised.")
#     c.save()

#     # Convert PDF to JPEG
#     output_jpeg_path = "treatment_report.jpg"
#     images = convert_from_path(pdf_path)
#     images[0].save(output_jpeg_path, 'JPEG')

#     # Return JPEG
#     return FileResponse(path=output_jpeg_path, filename="treatment_report.jpg", media_type='image/jpeg')


   
